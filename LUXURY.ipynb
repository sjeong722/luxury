{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d6117f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 불러오기\n",
    "posts = pd.read_csv(\"data/cafe_posts_clean.csv\")     \n",
    "\n",
    "# 50개 행을 랜덤 추출 (랜덤 시드 고정하면 재현 가능)\n",
    "sample_posts = posts.sample(n=50, random_state=42)\n",
    "\n",
    "# 결과 확인\n",
    "print(sample_posts.shape)\n",
    "print(sample_posts.head())\n",
    "\n",
    "# 필요하다면 파일로 저장\n",
    "sample_posts.to_csv(\"data/cafe_posts_sample50.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"✅ 50개 샘플 저장 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5641eb6",
   "metadata": {},
   "source": [
    "핸들 샘플링 과정\n",
    "1. 매장명 동의어 -> 대표성 텍스트로 분류하여 추출 \n",
    "    : 매장명 리스트 [사전]필요. jewerly_place_with_brandname\n",
    "2. 매장명이 언급된 게시글의 번호, 브랜드, 감정분류 \n",
    "    columns : article_id, brand_name, sentiment\n",
    "    : 감정분류 [사전] 필요. place_sentiment_keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a4c657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "\n",
    "# -----------------------------\n",
    "# 공통 유틸\n",
    "# -----------------------------\n",
    "def find_column(df: pd.DataFrame, candidates: list[str]) -> str | None:\n",
    "    \"\"\"대소문자/공백 무시하고 후보 중 존재하는 첫 컬럼명을 찾아 반환\"\"\"\n",
    "    norm = {c.lower().strip(): c for c in df.columns}\n",
    "    for cand in candidates:\n",
    "        key = cand.lower().strip()\n",
    "        if key in norm:\n",
    "            return norm[key]\n",
    "    return None\n",
    "\n",
    "def safe_text(row: pd.Series, col: str | None) -> str:\n",
    "    \"\"\"Series에서 안전하게 텍스트 추출 (없으면 빈 문자열)\"\"\"\n",
    "    if not col:\n",
    "        return \"\"\n",
    "    # pandas Series.get 사용 → 없으면 기본값 반환\n",
    "    return str(row.get(col, \"\") or \"\")\n",
    "\n",
    "# -----------------------------\n",
    "# 1) 데이터 불러오기 + 샘플링\n",
    "# -----------------------------\n",
    "def load_and_sample(filepath: str, n=50, random_state=42) -> pd.DataFrame:\n",
    "    df = pd.read_csv(filepath)\n",
    "    sample_df = df.sample(n=n, random_state=random_state)\n",
    "    return sample_df.reset_index(drop=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) 매장명 정규화\n",
    "# -----------------------------\n",
    "def load_place_dict(path: str) -> dict:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def normalize_place(text: str, place_dict: dict) -> str | None:\n",
    "    # 동의어는 정규식 특수문자 이스케이프 + 대소문자 무시\n",
    "    for standard, synonyms in place_dict.items():\n",
    "        for syn in synonyms:\n",
    "            if syn and re.search(re.escape(syn), text, flags=re.IGNORECASE):\n",
    "                return standard\n",
    "    return None\n",
    "\n",
    "# -----------------------------\n",
    "# 3) 감정 분류 (카테고리별)\n",
    "# -----------------------------\n",
    "def load_sentiment_dict(path: str) -> dict:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def classify_sentiment(text: str, sentiment_dict: dict) -> str:\n",
    "    # sentiment_dict의 key가 \"인테리어_긍정\" 같은 카테고리라고 가정\n",
    "    for category, keywords in sentiment_dict.items():\n",
    "        if any(kw and kw in text for kw in keywords):\n",
    "            return category\n",
    "    return \"기타_중립\"  # 매칭 없으면 기본 라벨\n",
    "\n",
    "# -----------------------------\n",
    "# 4) 실행 부분\n",
    "# -----------------------------\n",
    "def main():\n",
    "    # ✅ 파일 경로: JSON 확장자 확인!\n",
    "    CLEAN_FILE = \"data/cafe_posts_clean.csv\"\n",
    "    PLACE_DICT_FILE = \"data/jewelry_place_dict.json\"\n",
    "    SENTIMENT_DICT_FILE = \"data/place_sentiment_keywords_by_category.json\"\n",
    "\n",
    "    # 1) 샘플링\n",
    "    df = load_and_sample(CLEAN_FILE, n=50, random_state=42)\n",
    "\n",
    "    # 2) 컬럼 자동 감지\n",
    "    naver_article_id_col = find_column(df, [\"naver_article_id\", \"post_id\", \"id\", \"글번호\", \"번호\", \"no\"])\n",
    "    title_col      = find_column(df, [\"title\", \"제목\"])\n",
    "    text_col       = find_column(df, [\"text\", \"본문\", \"내용\"])\n",
    "    comments_col   = find_column(df, [\"comments\", \"comment\", \"댓글\", \"코멘트\"])\n",
    "\n",
    "    # 참고용: 어떤 컬럼이 매핑됐는지 출력\n",
    "    print(\"[Column mapping]\")\n",
    "    print(\" naver_article_id_col:\", naver_article_id_col)\n",
    "    print(\" title_col     :\", title_col)\n",
    "    print(\" text_col      :\", text_col)\n",
    "    print(\" comments_col  :\", comments_col)\n",
    "\n",
    "    # 3) 사전 로드\n",
    "    place_dict     = load_place_dict(PLACE_DICT_FILE)\n",
    "    sentiment_dict = load_sentiment_dict(SENTIMENT_DICT_FILE)\n",
    "\n",
    "    # 4) 라벨링\n",
    "    results = []\n",
    "    for idx, row in df.iterrows():\n",
    "        # 텍스트 구성: 없으면 빈 문자열로 안전 처리\n",
    "        text = \" \".join([\n",
    "            safe_text(row, title_col),\n",
    "            safe_text(row, text_col),\n",
    "            safe_text(row, comments_col),\n",
    "        ])\n",
    "\n",
    "        place = normalize_place(text, place_dict)\n",
    "        category_sentiment = classify_sentiment(text, sentiment_dict)\n",
    "\n",
    "        if place:  # 매장 언급된 경우만\n",
    "            # ✅ article_id가 없으면 인덱스로 대체\n",
    "            article_id = row.get(naver_article_id_col, idx) if naver_article_id_col else idx\n",
    "            results.append({\n",
    "                \"article_id\": article_id,\n",
    "                # 원래 요구 컬럼명이 brand_name이었지만, 실제로는 '매장명'이 들어가므로 혼동이면 'place_name'으로 쓰는 걸 권장\n",
    "                \"brand_name\": place,  # 필요 시 \"place_name\": place 로 변경 권장\n",
    "                \"sentiment\": category_sentiment\n",
    "            })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(\"\\n=== 라벨링 결과 미리보기 (gkdnl 10행) ===\")\n",
    "    print(results_df.tail(10))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f65179",
   "metadata": {},
   "source": [
    "하이브리드 방식: LLM+dict / 사전에 있으면 그대로 출력, 없으면 LLM 으로 분류해서 출력."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58ede92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai  # ✅ Gemini SDK\n",
    "\n",
    "# ------------------------\n",
    "# ① 환경설정 & API 키 불러오기\n",
    "# ------------------------\n",
    "load_dotenv()\n",
    "google_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if not google_key:\n",
    "    raise ValueError(\"환경변수 GOOGLE_API_KEY가 없습니다. .env 파일 확인!\")\n",
    "\n",
    "# ------------------------\n",
    "# ② Gemini 클라이언트 초기화\n",
    "# ------------------------\n",
    "genai.configure(api_key=google_key)\n",
    "gemini_model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 1) 데이터 불러오기 + 샘플링\n",
    "# -----------------------------\n",
    "def load_and_sample(filepath: str, n=50, random_state=42) -> pd.DataFrame:\n",
    "    df = pd.read_csv(filepath)\n",
    "    sample_df = df.sample(n=n, random_state=random_state)\n",
    "    return sample_df.reset_index(drop=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) 매장명 정규화 (Rule 기반)\n",
    "# -----------------------------\n",
    "def load_place_dict(path: str) -> dict:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def normalize_place_rule(text: str, place_dict: dict) -> str | None:\n",
    "    for standard, synonyms in place_dict.items():\n",
    "        for syn in synonyms:\n",
    "            if syn and re.search(re.escape(syn), text, flags=re.IGNORECASE):\n",
    "                return standard\n",
    "    return None\n",
    "\n",
    "# -----------------------------\n",
    "# 3) 감정 분류 (Rule 기반)\n",
    "# -----------------------------\n",
    "def load_sentiment_dict(path: str) -> dict:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def classify_sentiment_rule(text: str, sentiment_dict: dict) -> str | None:\n",
    "    for category, keywords in sentiment_dict.items():\n",
    "        if any(kw in text for kw in keywords):\n",
    "            return category\n",
    "    return None\n",
    "\n",
    "# -----------------------------\n",
    "# 4) LLM 보완\n",
    "# -----------------------------\n",
    "def classify_with_llm(text: str, place_dict: dict, sentiment_categories: list[str]) -> tuple[str, str]:\n",
    "    prompt = f\"\"\"\n",
    "    다음 텍스트에서 언급된 매장명을 표준 매장명으로 추출하고,\n",
    "    감정은 아래 카테고리 중 가장 적합한 하나를 선택해줘.\n",
    "\n",
    "    텍스트: {text}\n",
    "\n",
    "    매장 후보 (예시): {list(place_dict.keys())[:20]} ...  # 전체가 너무 많으면 일부만 예시 제공\n",
    "\n",
    "    감정 카테고리 후보:\n",
    "    {sentiment_categories}\n",
    "\n",
    "    출력 형식:\n",
    "    매장명: <표준매장명 또는 None>\n",
    "    감정: <카테고리>\n",
    "    출력은 반드시 JSON 형식으로만 해.\n",
    "    예: {\"매장명\": \"현대백화점 무역센터점\", \"감정\": \"인테리어_긍정\"}\n",
    "    \"\"\"\n",
    "\n",
    "    response = gemini_model.generate_content(prompt)\n",
    "    answer = response.text.strip()\n",
    "\n",
    "    place, sentiment = None, \"기타_중립\"\n",
    "    for line in answer.splitlines():\n",
    "        if line.startswith(\"매장명:\"):\n",
    "            place = line.replace(\"매장명:\", \"\").strip()\n",
    "        if line.startswith(\"감정:\"):\n",
    "            sentiment = line.replace(\"감정:\", \"\").strip()\n",
    "\n",
    "    return place, sentiment\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 5) 실행 부분 (Hybrid 적용)\n",
    "# -----------------------------\n",
    "def main():\n",
    "    CLEAN_FILE = \"data/cafe_posts_clean.csv\"\n",
    "    PLACE_DICT_FILE = \"data/jewelry_place_dict.json\"\n",
    "    SENTIMENT_DICT_FILE = \"data/place_sentiment_keywords_by_category.json\"\n",
    "\n",
    "    df = load_and_sample(CLEAN_FILE, n=50, random_state=42)\n",
    "    place_dict = load_place_dict(PLACE_DICT_FILE)\n",
    "    sentiment_dict = load_sentiment_dict(SENTIMENT_DICT_FILE)\n",
    "    sentiment_categories = list(sentiment_dict.keys())\n",
    "\n",
    "    results = []\n",
    "    for idx, row in df.iterrows():\n",
    "        text = f\"{row.get('title','')} {row.get('text','')} {row.get('comments','')}\"\n",
    "\n",
    "        # 1) Rule 기반 먼저 시도\n",
    "        place = normalize_place_rule(text, place_dict)\n",
    "        sentiment = classify_sentiment_rule(text, sentiment_dict)\n",
    "\n",
    "        # 2) Rule 실패 시 LLM 호출\n",
    "        if not place or not sentiment:\n",
    "            place_llm, sentiment_llm = classify_with_llm(text, place_dict, sentiment_categories)\n",
    "            place = place or place_llm\n",
    "            sentiment = sentiment or sentiment_llm\n",
    "\n",
    "        if place:\n",
    "            results.append({\n",
    "                \"article_id\": row.get(\"article_id\", idx),\n",
    "                \"place_name\": place,\n",
    "                \"sentiment\": sentiment\n",
    "            })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(\"\\n=== 라벨링 결과 미리보기 (상위 10행) ===\")\n",
    "    print(results_df.head(10))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdd4e57",
   "metadata": {},
   "source": [
    "게시글번호 naver_article_id 반영되도록."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d91718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai  # Gemini SDK\n",
    "\n",
    "# ------------------------\n",
    "# ① 환경설정 & API 키 불러오기\n",
    "# ------------------------\n",
    "load_dotenv()\n",
    "google_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if not google_key:\n",
    "    raise ValueError(\"환경변수 GOOGLE_API_KEY가 없습니다. .env 파일 확인!\")\n",
    "\n",
    "# ------------------------\n",
    "# ② Gemini 클라이언트 초기화\n",
    "# ------------------------\n",
    "genai.configure(api_key=google_key)\n",
    "gemini_model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "# -----------------------------\n",
    "# 1) 데이터 불러오기 + 샘플링\n",
    "# -----------------------------\n",
    "def load_and_sample(filepath: str, n=50, random_state=42) -> pd.DataFrame:\n",
    "    df = pd.read_csv(filepath)\n",
    "    sample_df = df.sample(n=n, random_state=random_state)\n",
    "    return sample_df.reset_index(drop=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) 매장명 정규화 (Rule 기반)\n",
    "# -----------------------------\n",
    "def load_place_dict(path: str) -> dict:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def normalize_place_rule(text: str, place_dict: dict) -> str | None:\n",
    "    for standard, synonyms in place_dict.items():\n",
    "        for syn in synonyms:\n",
    "            if syn and re.search(re.escape(syn), text, flags=re.IGNORECASE):\n",
    "                return standard\n",
    "    return None\n",
    "\n",
    "# -----------------------------\n",
    "# 3) 감정 분류 (Rule 기반)\n",
    "# -----------------------------\n",
    "def load_sentiment_dict(path: str) -> dict:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def classify_sentiment_rule(text: str, sentiment_dict: dict) -> str | None:\n",
    "    for category, keywords in sentiment_dict.items():\n",
    "        if any(kw in text for kw in keywords):\n",
    "            return category\n",
    "    return None\n",
    "\n",
    "# -----------------------------\n",
    "# 4) LLM 보완 (Gemini)\n",
    "# -----------------------------\n",
    "def classify_with_llm(text: str, place_dict: dict, sentiment_categories: list[str]) -> tuple[str, str]:\n",
    "    prompt = f\"\"\"\n",
    "    다음 텍스트에서 언급된 매장명을 표준 매장명으로 추출하고,\n",
    "    감정은 아래 카테고리 중 가장 적합한 하나를 선택해줘.\n",
    "\n",
    "    텍스트: {text}\n",
    "\n",
    "    매장 후보 (예시): {list(place_dict.keys())[:20]}\n",
    "\n",
    "    감정 카테고리 후보:\n",
    "    {sentiment_categories}\n",
    "\n",
    "    출력 형식:\n",
    "    매장명: <표준매장명 또는 None>\n",
    "    감정: <카테고리>\n",
    "    \"\"\"\n",
    "\n",
    "    response = gemini_model.generate_content(prompt)\n",
    "    answer = response.text.strip()\n",
    "\n",
    "    place, sentiment = None, \"기타_중립\"\n",
    "    for line in answer.splitlines():\n",
    "        if line.startswith(\"매장명:\"):\n",
    "            place = line.replace(\"매장명:\", \"\").strip()\n",
    "        if line.startswith(\"감정:\"):\n",
    "            sentiment = line.replace(\"감정:\", \"\").strip()\n",
    "\n",
    "    return place, sentiment\n",
    "\n",
    "# -----------------------------\n",
    "# 5) 실행 부분 (Hybrid 적용)\n",
    "# -----------------------------\n",
    "def main():\n",
    "    CLEAN_FILE = \"data/cafe_posts_clean.csv\"\n",
    "    PLACE_DICT_FILE = \"data/jewelry_place_dict.json\"\n",
    "    SENTIMENT_DICT_FILE = \"data/place_sentiment_keywords_by_category.json\"\n",
    "\n",
    "    df = load_and_sample(CLEAN_FILE, n=50, random_state=42)\n",
    "    place_dict = load_place_dict(PLACE_DICT_FILE)\n",
    "    sentiment_dict = load_sentiment_dict(SENTIMENT_DICT_FILE)\n",
    "    sentiment_categories = list(sentiment_dict.keys())\n",
    "\n",
    "    results = []\n",
    "    for _, row in df.iterrows():\n",
    "        text = f\"{row.get('title','')} {row.get('text','')} {row.get('comments','')}\"\n",
    "\n",
    "        # 1) Rule 기반 먼저 시도\n",
    "        place = normalize_place_rule(text, place_dict)\n",
    "        sentiment = classify_sentiment_rule(text, sentiment_dict)\n",
    "\n",
    "        # 2) Rule 실패 시 LLM 호출\n",
    "        if not place or not sentiment:\n",
    "            place_llm, sentiment_llm = classify_with_llm(text, place_dict, sentiment_categories)\n",
    "            place = place or place_llm\n",
    "            sentiment = sentiment or sentiment_llm\n",
    "\n",
    "        if place:\n",
    "            results.append({\n",
    "                \"article_id\": row.get(\"naver_article_id\", None),  # ✅ 네이버 게시글 번호\n",
    "                \"place_name\": place,\n",
    "                \"sentiment\": sentiment\n",
    "            })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(\"\\n=== 라벨링 결과 미리보기 (상위 10행) ===\")\n",
    "    print(results_df.head(10))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5965be",
   "metadata": {},
   "source": [
    "pbrand_name, location_lv1, location_lv2 정보도 구분할 수 있게 dic.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ae829d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai  # Gemini SDK\n",
    "\n",
    "# ------------------------\n",
    "# ① 환경설정 & API 키 불러오기\n",
    "# ------------------------\n",
    "load_dotenv()\n",
    "google_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if not google_key:\n",
    "    raise ValueError(\"환경변수 GOOGLE_API_KEY가 없습니다. .env 파일 확인!\")\n",
    "\n",
    "# ------------------------\n",
    "# ② Gemini 클라이언트 초기화\n",
    "# ------------------------\n",
    "genai.configure(api_key=google_key)\n",
    "gemini_model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "# -----------------------------\n",
    "# 1) 데이터 불러오기 + 샘플링\n",
    "# -----------------------------\n",
    "def load_and_sample(filepath: str, n=50, random_state=42) -> pd.DataFrame:\n",
    "    df = pd.read_csv(filepath)\n",
    "    sample_df = df.sample(n=n, random_state=random_state)\n",
    "    return sample_df.reset_index(drop=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) 매장명 정규화 (Rule 기반)\n",
    "# -----------------------------\n",
    "def load_place_info_dict(path: str) -> dict:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def normalize_place_rule(text: str, place_info_dict: dict) -> str | None:\n",
    "    for standard, info in place_info_dict.items():\n",
    "        for syn in info[\"synonyms\"]:\n",
    "            if syn and re.search(re.escape(syn), text, flags=re.IGNORECASE):\n",
    "                return standard\n",
    "    return None\n",
    "\n",
    "# -----------------------------\n",
    "# 3) 감정 분류 (Rule 기반)\n",
    "# -----------------------------\n",
    "def load_sentiment_dict(path: str) -> dict:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def classify_sentiment_rule(text: str, sentiment_dict: dict) -> str | None:\n",
    "    for category, keywords in sentiment_dict.items():\n",
    "        if any(kw in text for kw in keywords):\n",
    "            return category\n",
    "    return None\n",
    "\n",
    "# -----------------------------\n",
    "# 4) LLM 보완 (Gemini)\n",
    "# -----------------------------\n",
    "def classify_with_llm(text: str, place_info_dict: dict, sentiment_categories: list[str]) -> tuple[str, str]:\n",
    "    prompt = f\"\"\"\n",
    "    다음 텍스트에서 언급된 매장명을 표준 매장명으로 추출하고,\n",
    "    감정은 아래 카테고리 중 가장 적합한 하나를 선택해줘.\n",
    "\n",
    "    텍스트: {text}\n",
    "\n",
    "    매장 후보 (예시): {list(place_info_dict.keys())[:20]}\n",
    "\n",
    "    감정 카테고리 후보:\n",
    "    {sentiment_categories}\n",
    "\n",
    "    출력 형식:\n",
    "    매장명: <표준매장명 또는 None>\n",
    "    감정: <카테고리>\n",
    "    \"\"\"\n",
    "\n",
    "    response = gemini_model.generate_content(prompt)\n",
    "    answer = response.text.strip()\n",
    "\n",
    "    place, sentiment = None, \"기타_중립\"\n",
    "    for line in answer.splitlines():\n",
    "        if line.startswith(\"매장명:\"):\n",
    "            place = line.replace(\"매장명:\", \"\").strip()\n",
    "        if line.startswith(\"감정:\"):\n",
    "            sentiment = line.replace(\"감정:\", \"\").strip()\n",
    "\n",
    "    return place, sentiment\n",
    "\n",
    "# -----------------------------\n",
    "# 5) 실행 부분 (Hybrid 적용)\n",
    "# -----------------------------\n",
    "def main():\n",
    "    CLEAN_FILE = \"data/cafe_posts_clean.csv\"\n",
    "    PLACE_INFO_FILE = \"data/jewelry_place_info_dict.json\"   # ✅ 새로운 JSON\n",
    "    SENTIMENT_DICT_FILE = \"data/place_sentiment_keywords_by_category.json\"\n",
    "\n",
    "    df = load_and_sample(CLEAN_FILE, n=50, random_state=42)\n",
    "    place_info_dict = load_place_info_dict(PLACE_INFO_FILE)\n",
    "    sentiment_dict = load_sentiment_dict(SENTIMENT_DICT_FILE)\n",
    "    sentiment_categories = list(sentiment_dict.keys())\n",
    "\n",
    "    results = []\n",
    "    for _, row in df.iterrows():\n",
    "        text = f\"{row.get('title','')} {row.get('text','')} {row.get('comments','')}\"\n",
    "\n",
    "        # 1) Rule 기반 먼저 시도\n",
    "        place = normalize_place_rule(text, place_info_dict)\n",
    "        sentiment = classify_sentiment_rule(text, sentiment_dict)\n",
    "\n",
    "        # 2) Rule 실패 시 LLM 호출\n",
    "        if not place or not sentiment:\n",
    "            place_llm, sentiment_llm = classify_with_llm(text, place_info_dict, sentiment_categories)\n",
    "            place = place or place_llm\n",
    "            sentiment = sentiment or sentiment_llm\n",
    "\n",
    "        if place:\n",
    "            info = place_info_dict.get(place, {})\n",
    "            results.append({\n",
    "                \"article_id\": row.get(\"naver_article_id\", None),\n",
    "                \"place_name\": place,\n",
    "                \"pbrand_name\": info.get(\"pbrand_name\"),\n",
    "                \"location_lv1\": info.get(\"location_lv1\"),\n",
    "                \"location_lv2\": info.get(\"location_lv2\"),\n",
    "                \"sentiment\": sentiment\n",
    "            })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(\"\\n=== 라벨링 결과 미리보기 (상위 10행) ===\")\n",
    "    print(results_df.head(10))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1315fc",
   "metadata": {},
   "source": [
    "조건 필터 추가: place_name, pbrand_name, location_lv1, location_lv2 모두 None/\"None\"이면 결과에서 제외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d60aa7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai  #  Gemini SDK\n",
    "\n",
    "# ------------------------\n",
    "# ① 환경설정 & API 키 불러오기\n",
    "# ------------------------\n",
    "load_dotenv()\n",
    "google_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if not google_key:\n",
    "    raise ValueError(\"환경변수 GOOGLE_API_KEY가 없습니다. .env 파일 확인!\")\n",
    "\n",
    "# ------------------------\n",
    "# ② Gemini 클라이언트 초기화\n",
    "# ------------------------\n",
    "genai.configure(api_key=google_key)\n",
    "gemini_model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "# -----------------------------\n",
    "# 1) 데이터 불러오기 + 샘플링\n",
    "# -----------------------------\n",
    "def load_and_sample(filepath: str, n=50, random_state=42) -> pd.DataFrame:\n",
    "    df = pd.read_csv(filepath)\n",
    "    sample_df = df.sample(n=n, random_state=random_state)\n",
    "    return sample_df.reset_index(drop=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) 매장명 정규화 (Rule 기반)\n",
    "# -----------------------------\n",
    "def load_place_info_dict(path: str) -> dict:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def normalize_place_rule(text: str, place_info_dict: dict) -> str | None:\n",
    "    for standard, info in place_info_dict.items():\n",
    "        for syn in info[\"synonyms\"]:\n",
    "            if syn and re.search(re.escape(syn), text, flags=re.IGNORECASE):\n",
    "                return standard\n",
    "    return None\n",
    "\n",
    "# -----------------------------\n",
    "# 3) 감정 분류 (Rule 기반)\n",
    "# -----------------------------\n",
    "def load_sentiment_dict(path: str) -> dict:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def classify_sentiment_rule(text: str, sentiment_dict: dict) -> str | None:\n",
    "    for category, keywords in sentiment_dict.items():\n",
    "        if any(kw in text for kw in keywords):\n",
    "            return category\n",
    "    return None\n",
    "\n",
    "# -----------------------------\n",
    "# 4) LLM 보완 (Gemini)\n",
    "# -----------------------------\n",
    "def classify_with_llm(text: str, place_info_dict: dict, sentiment_categories: list[str]) -> tuple[str, str]:\n",
    "    prompt = f\"\"\"\n",
    "    다음 텍스트에서 언급된 매장명을 표준 매장명으로 추출하고,\n",
    "    감정은 아래 카테고리 중 가장 적합한 하나를 선택해줘.\n",
    "\n",
    "    텍스트: {text}\n",
    "\n",
    "    매장 후보 (예시): {list(place_info_dict.keys())[:20]}\n",
    "\n",
    "    감정 카테고리 후보:\n",
    "    {sentiment_categories}\n",
    "\n",
    "    출력 형식:\n",
    "    매장명: <표준매장명 또는 None>\n",
    "    감정: <카테고리>\n",
    "    \"\"\"\n",
    "\n",
    "    response = gemini_model.generate_content(prompt)\n",
    "    answer = response.text.strip()\n",
    "\n",
    "    place, sentiment = None, \"기타_중립\"\n",
    "    for line in answer.splitlines():\n",
    "        if line.startswith(\"매장명:\"):\n",
    "            place = line.replace(\"매장명:\", \"\").strip()\n",
    "        if line.startswith(\"감정:\"):\n",
    "            sentiment = line.replace(\"감정:\", \"\").strip()\n",
    "\n",
    "    return place, sentiment\n",
    "\n",
    "# -----------------------------\n",
    "# 5) 실행 부분 (Hybrid 적용)\n",
    "# -----------------------------\n",
    "def main():\n",
    "    CLEAN_FILE = \"data/cafe_posts_clean.csv\"\n",
    "    PLACE_INFO_FILE = \"data/jewelry_place_info_dict.json\"   # 새로운 JSON\n",
    "    SENTIMENT_DICT_FILE = \"data/place_sentiment_keywords_by_category.json\"\n",
    "\n",
    "    df = load_and_sample(CLEAN_FILE, n=50, random_state=42)\n",
    "    place_info_dict = load_place_info_dict(PLACE_INFO_FILE)\n",
    "    sentiment_dict = load_sentiment_dict(SENTIMENT_DICT_FILE)\n",
    "    sentiment_categories = list(sentiment_dict.keys())\n",
    "\n",
    "    results = []\n",
    "    for _, row in df.iterrows():\n",
    "        text = f\"{row.get('title','')} {row.get('text','')} {row.get('comments','')}\"\n",
    "\n",
    "        # 1) Rule 기반 먼저 시도\n",
    "        place = normalize_place_rule(text, place_info_dict)\n",
    "        sentiment = classify_sentiment_rule(text, sentiment_dict)\n",
    "\n",
    "        # 2) Rule 실패 시 LLM 호출\n",
    "        if not place or not sentiment:\n",
    "            place_llm, sentiment_llm = classify_with_llm(text, place_info_dict, sentiment_categories)\n",
    "            place = place or place_llm\n",
    "            sentiment = sentiment or sentiment_llm\n",
    "\n",
    "        if place:\n",
    "            info = place_info_dict.get(place, {})\n",
    "            record = {\n",
    "                \"article_id\": row.get(\"naver_article_id\", None),\n",
    "                \"place_name\": place,\n",
    "                \"pbrand_name\": info.get(\"pbrand_name\"),\n",
    "                \"location_lv1\": info.get(\"location_lv1\"),\n",
    "                \"location_lv2\": info.get(\"location_lv2\"),\n",
    "                \"sentiment\": sentiment\n",
    "            }\n",
    "\n",
    "            # ✅ 모두 None 또는 \"None\"이면 제외\n",
    "            if not all((record.get(k) is None or record.get(k) == \"None\") for k in [\"place_name\", \"pbrand_name\", \"location_lv1\", \"location_lv2\"]):\n",
    "                results.append(record)\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(\"\\n=== 라벨링 결과 미리보기 (상위 10행) ===\")\n",
    "    print(results_df.head(10))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca54c6fc",
   "metadata": {},
   "source": [
    "sentiment에서 친절에 관한 레코드만 출력되도록."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83dd7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai  # Gemini SDK\n",
    "\n",
    "# ------------------------\n",
    "# ① 환경설정 & API 키 불러오기\n",
    "# ------------------------\n",
    "load_dotenv()\n",
    "google_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if not google_key:\n",
    "    raise ValueError(\"환경변수 GOOGLE_API_KEY가 없습니다. .env 파일 확인!\")\n",
    "\n",
    "# ------------------------\n",
    "# ② Gemini 클라이언트 초기화\n",
    "# ------------------------\n",
    "genai.configure(api_key=google_key)\n",
    "gemini_model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "# -----------------------------\n",
    "# 1) 데이터 불러오기 + 샘플링\n",
    "# -----------------------------\n",
    "def load_and_sample(filepath: str, n=50, random_state=42) -> pd.DataFrame:\n",
    "    df = pd.read_csv(filepath)\n",
    "    sample_df = df.sample(n=n, random_state=random_state)\n",
    "    return sample_df.reset_index(drop=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) 매장명 정규화 (Rule 기반)\n",
    "# -----------------------------\n",
    "def load_place_info_dict(path: str) -> dict:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def normalize_place_rule(text: str, place_info_dict: dict) -> str | None:\n",
    "    for standard, info in place_info_dict.items():\n",
    "        for syn in info[\"synonyms\"]:\n",
    "            if syn and re.search(re.escape(syn), text, flags=re.IGNORECASE):\n",
    "                return standard\n",
    "    return None\n",
    "\n",
    "# -----------------------------\n",
    "# 3) 감정 분류 (Rule 기반)\n",
    "# -----------------------------\n",
    "def load_sentiment_dict(path: str) -> dict:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def classify_sentiment_rule(text: str, sentiment_dict: dict) -> str | None:\n",
    "    for category, keywords in sentiment_dict.items():\n",
    "        if any(kw in text for kw in keywords):\n",
    "            return category\n",
    "    return None\n",
    "\n",
    "# -----------------------------\n",
    "# 4) LLM 보완 (Gemini)\n",
    "# -----------------------------\n",
    "def classify_with_llm(text: str, place_info_dict: dict, sentiment_categories: list[str]) -> tuple[str, str]:\n",
    "    prompt = f\"\"\"\n",
    "    다음 텍스트에서 언급된 매장명을 표준 매장명으로 추출하고,\n",
    "    감정은 아래 카테고리 중 가장 적합한 하나를 선택해줘.\n",
    "\n",
    "    텍스트: {text}\n",
    "\n",
    "    매장 후보 (예시): {list(place_info_dict.keys())[:20]}\n",
    "\n",
    "    감정 카테고리 후보:\n",
    "    {sentiment_categories}\n",
    "\n",
    "    출력 형식:\n",
    "    매장명: <표준매장명 또는 None>\n",
    "    감정: <카테고리>\n",
    "    \"\"\"\n",
    "\n",
    "    response = gemini_model.generate_content(prompt)\n",
    "    answer = response.text.strip()\n",
    "\n",
    "    place, sentiment = None, \"기타_중립\"\n",
    "    for line in answer.splitlines():\n",
    "        if line.startswith(\"매장명:\"):\n",
    "            place = line.replace(\"매장명:\", \"\").strip()\n",
    "        if line.startswith(\"감정:\"):\n",
    "            sentiment = line.replace(\"감정:\", \"\").strip()\n",
    "\n",
    "    return place, sentiment\n",
    "\n",
    "# -----------------------------\n",
    "# 5) 실행 부분 (Hybrid 적용)\n",
    "# -----------------------------\n",
    "def main():\n",
    "    CLEAN_FILE = \"data/cafe_posts_clean.csv\"\n",
    "    PLACE_INFO_FILE = \"data/jewelry_place_info_dict.json\"   # 새로운 JSON\n",
    "    SENTIMENT_DICT_FILE = \"data/place_sentiment_keywords_by_category.json\"\n",
    "\n",
    "    df = load_and_sample(CLEAN_FILE, n=50, random_state=42)\n",
    "    place_info_dict = load_place_info_dict(PLACE_INFO_FILE)\n",
    "    sentiment_dict = load_sentiment_dict(SENTIMENT_DICT_FILE)\n",
    "    sentiment_categories = list(sentiment_dict.keys())\n",
    "\n",
    "    results = []\n",
    "    for _, row in df.iterrows():\n",
    "        text = f\"{row.get('title','')} {row.get('text','')} {row.get('comments','')}\"\n",
    "\n",
    "        # 1) Rule 기반 먼저 시도\n",
    "        place = normalize_place_rule(text, place_info_dict)\n",
    "        sentiment = classify_sentiment_rule(text, sentiment_dict)\n",
    "\n",
    "        # 2) Rule 실패 시 LLM 호출\n",
    "        if not place or not sentiment:\n",
    "            place_llm, sentiment_llm = classify_with_llm(text, place_info_dict, sentiment_categories)\n",
    "            place = place or place_llm\n",
    "            sentiment = sentiment or sentiment_llm\n",
    "\n",
    "        if place:\n",
    "            info = place_info_dict.get(place, {})\n",
    "            record = {\n",
    "                \"article_id\": row.get(\"naver_article_id\", None),\n",
    "                \"place_name\": place,\n",
    "                \"pbrand_name\": info.get(\"pbrand_name\"),\n",
    "                \"location_lv1\": info.get(\"location_lv1\"),\n",
    "                \"location_lv2\": info.get(\"location_lv2\"),\n",
    "                \"sentiment\": sentiment\n",
    "            }\n",
    "\n",
    "            # 모두 None 또는 \"None\"이면 제외\n",
    "            if not all((record.get(k) is None or record.get(k) == \"None\") for k in [\"place_name\", \"pbrand_name\", \"location_lv1\", \"location_lv2\"]):\n",
    "                results.append(record)\n",
    "                \n",
    "\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(\"\\n=== 라벨링 결과 미리보기 (상위 10행) ===\")\n",
    "    print(results_df.head(10))\n",
    "    \n",
    "    # # ✅ 친절 관련 감정만 필터링 \n",
    "    # results_df = results_df[results_df[\"sentiment\"].str.contains(\"친절\", na=False)]\n",
    "    # 이렇게 하면 바로 위에서 지정한 상위 10행만 저장됨. (친절 필터링 없이 전체 sentiment)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f89677c",
   "metadata": {},
   "source": [
    "sentiment 필터링 없이 전체 CSV로 저장 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5cd1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai  # Gemini SDK\n",
    "\n",
    "# ------------------------\n",
    "# ① 환경설정 & API 키 불러오기\n",
    "# ------------------------\n",
    "load_dotenv()\n",
    "google_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if not google_key:\n",
    "    raise ValueError(\"환경변수 GOOGLE_API_KEY가 없습니다. .env 파일 확인!\")\n",
    "\n",
    "# ------------------------\n",
    "# ② Gemini 클라이언트 초기화\n",
    "# ------------------------\n",
    "genai.configure(api_key=google_key)\n",
    "gemini_model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "# ------------------------\n",
    "# ✅ CSV 저장 헬퍼 함수\n",
    "# ------------------------\n",
    "def save_csv(df: pd.DataFrame, path: str):\n",
    "    \"\"\"DataFrame을 안전하게 CSV로 저장\"\"\"\n",
    "    df.to_csv(path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"✅ CSV 저장 완료: {path}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 1) 데이터 불러오기 + 샘플링\n",
    "# -----------------------------\n",
    "def load_and_sample(filepath: str, n=50, random_state=42) -> pd.DataFrame:\n",
    "    df = pd.read_csv(filepath)\n",
    "    sample_df = df.sample(n=n, random_state=random_state)\n",
    "    return sample_df.reset_index(drop=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) 매장명 정규화 (Rule 기반)\n",
    "# -----------------------------\n",
    "def load_place_info_dict(path: str) -> dict:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def normalize_place_rule(text: str, place_info_dict: dict) -> str | None:\n",
    "    for standard, info in place_info_dict.items():\n",
    "        for syn in info[\"synonyms\"]:\n",
    "            if syn and re.search(re.escape(syn), text, flags=re.IGNORECASE):\n",
    "                return standard\n",
    "    return None\n",
    "\n",
    "# -----------------------------\n",
    "# 3) 감정 분류 (Rule 기반)\n",
    "# -----------------------------\n",
    "def load_sentiment_dict(path: str) -> dict:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def classify_sentiment_rule(text: str, sentiment_dict: dict) -> str | None:\n",
    "    for category, keywords in sentiment_dict.items():\n",
    "        if any(kw in text for kw in keywords):\n",
    "            return category\n",
    "    return None\n",
    "\n",
    "# -----------------------------\n",
    "# 4) LLM 보완 (Gemini)\n",
    "# -----------------------------\n",
    "def classify_with_llm(text: str, place_info_dict: dict, sentiment_categories: list[str]) -> tuple[str, str]:\n",
    "    prompt = f\"\"\"\n",
    "    다음 텍스트에서 언급된 매장명을 표준 매장명으로 추출하고,\n",
    "    감정은 아래 카테고리 중 가장 적합한 하나를 선택해줘.\n",
    "\n",
    "    텍스트: {text}\n",
    "\n",
    "    매장 후보 (예시): {list(place_info_dict.keys())[:20]}\n",
    "\n",
    "    감정 카테고리 후보:\n",
    "    {sentiment_categories}\n",
    "\n",
    "    출력 형식:\n",
    "    매장명: <표준매장명 또는 None>\n",
    "    감정: <카테고리>\n",
    "    \"\"\"\n",
    "\n",
    "    response = gemini_model.generate_content(prompt)\n",
    "    answer = response.text.strip()\n",
    "\n",
    "    place, sentiment = None, \"기타_중립\"\n",
    "    for line in answer.splitlines():\n",
    "        if line.startswith(\"매장명:\"):\n",
    "            place = line.replace(\"매장명:\", \"\").strip()\n",
    "        if line.startswith(\"감정:\"):\n",
    "            sentiment = line.replace(\"감정:\", \"\").strip()\n",
    "\n",
    "    return place, sentiment\n",
    "\n",
    "# -----------------------------\n",
    "# 5) 실행 부분 (Hybrid 적용)\n",
    "# -----------------------------\n",
    "def main():\n",
    "    CLEAN_FILE = \"data/cafe_posts_clean.csv\"\n",
    "    PLACE_INFO_FILE = \"data/jewelry_place_info_dict.json\"\n",
    "    SENTIMENT_DICT_FILE = \"data/place_sentiment_keywords_by_category.json\"\n",
    "\n",
    "    df = load_and_sample(CLEAN_FILE, n=50, random_state=42)\n",
    "    place_info_dict = load_place_info_dict(PLACE_INFO_FILE)\n",
    "    sentiment_dict = load_sentiment_dict(SENTIMENT_DICT_FILE)\n",
    "    sentiment_categories = list(sentiment_dict.keys())\n",
    "\n",
    "    results = []\n",
    "    for _, row in df.iterrows():\n",
    "        text = f\"{row.get('title','')} {row.get('text','')} {row.get('comments','')}\"\n",
    "\n",
    "        # 1) Rule 기반 먼저 시도\n",
    "        place = normalize_place_rule(text, place_info_dict)\n",
    "        sentiment = classify_sentiment_rule(text, sentiment_dict)\n",
    "\n",
    "        # 2) Rule 실패 시 LLM 호출\n",
    "        if not place or not sentiment:\n",
    "            place_llm, sentiment_llm = classify_with_llm(text, place_info_dict, sentiment_categories)\n",
    "            place = place or place_llm\n",
    "            sentiment = sentiment or sentiment_llm\n",
    "\n",
    "        if place:\n",
    "            info = place_info_dict.get(place, {})\n",
    "            record = {\n",
    "                \"article_id\": row.get(\"naver_article_id\", None),\n",
    "                \"place_name\": place,\n",
    "                \"pbrand_name\": info.get(\"pbrand_name\"),\n",
    "                \"location_lv1\": info.get(\"location_lv1\"),\n",
    "                \"location_lv2\": info.get(\"location_lv2\"),\n",
    "                \"sentiment\": sentiment\n",
    "            }\n",
    "\n",
    "            # 모두 None 또는 \"None\"이면 제외\n",
    "            if not all((record.get(k) is None or record.get(k) == \"None\") for k in [\"place_name\", \"pbrand_name\", \"location_lv1\", \"location_lv2\"]):\n",
    "                results.append(record)\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    # print(\"\\n=== 라벨링 결과 미리보기 (상위 5행) ===\")\n",
    "    # print(results_df.head(5))\n",
    "    \n",
    "    # ✅ 전체 결과 CSV 저장\n",
    "    OUTPUT_FILE = \"data/labeled_sample_sentiment.csv\"\n",
    "    save_csv(results_df, OUTPUT_FILE)\n",
    "\n",
    "   \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07da566",
   "metadata": {},
   "source": [
    "전체 결과인데 행이 15개 뿐? -> 정확도 대략 50% 나옴\n",
    "샘플 load_and_sample 함수 내 n=50 제거하고 전체 데이터 대상. \n",
    "하니까 너무 오래걸림.40분 됐는데 아직도 안끝남;; -> 97분에서 스탑. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d96e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai  # Gemini SDK\n",
    "\n",
    "# ------------------------\n",
    "# ① 환경설정 & API 키 불러오기\n",
    "# ------------------------\n",
    "load_dotenv()\n",
    "google_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if not google_key:\n",
    "    raise ValueError(\"환경변수 GOOGLE_API_KEY가 없습니다. .env 파일 확인!\")\n",
    "\n",
    "# ------------------------\n",
    "# ② Gemini 클라이언트 초기화\n",
    "# ------------------------\n",
    "genai.configure(api_key=google_key)\n",
    "gemini_model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "# ------------------------\n",
    "# CSV 저장 헬퍼 함수\n",
    "# ------------------------\n",
    "def save_csv(df: pd.DataFrame, path: str):\n",
    "    \"\"\"DataFrame을 안전하게 CSV로 저장\"\"\"\n",
    "    df.to_csv(path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\" CSV 저장 완료: {path}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 1) 데이터 불러오기 (✅전체 데이터 사용)\n",
    "# -----------------------------\n",
    "def load_data(filepath: str) -> pd.DataFrame:\n",
    "    \"\"\"CSV 파일 전체 불러오기\"\"\"\n",
    "    return pd.read_csv(filepath)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) 매장명 정규화 (Rule 기반)\n",
    "# -----------------------------\n",
    "def load_place_info_dict(path: str) -> dict:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def normalize_place_rule(text: str, place_info_dict: dict) -> str | None:\n",
    "    for standard, info in place_info_dict.items():\n",
    "        for syn in info[\"synonyms\"]:\n",
    "            if syn and re.search(re.escape(syn), text, flags=re.IGNORECASE):\n",
    "                return standard\n",
    "    return None\n",
    "\n",
    "# -----------------------------\n",
    "# 3) 감정 분류 (Rule 기반)\n",
    "# -----------------------------\n",
    "def load_sentiment_dict(path: str) -> dict:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def classify_sentiment_rule(text: str, sentiment_dict: dict) -> str | None:\n",
    "    for category, keywords in sentiment_dict.items():\n",
    "        if any(kw in text for kw in keywords):\n",
    "            return category\n",
    "    return None\n",
    "\n",
    "# -----------------------------\n",
    "# 4) LLM 보완 (Gemini)\n",
    "# -----------------------------\n",
    "def classify_with_llm(text: str, place_info_dict: dict, sentiment_categories: list[str]) -> tuple[str, str]:\n",
    "    prompt = f\"\"\"\n",
    "    다음 텍스트에서 언급된 매장명을 표준 매장명으로 추출하고,\n",
    "    감정은 아래 카테고리 중 가장 적합한 하나를 선택해줘.\n",
    "\n",
    "    텍스트: {text}\n",
    "\n",
    "    매장 후보 (예시): {list(place_info_dict.keys())[:20]}\n",
    "\n",
    "    감정 카테고리 후보:\n",
    "    {sentiment_categories}\n",
    "\n",
    "    출력 형식:\n",
    "    매장명: <표준매장명 또는 None>\n",
    "    감정: <카테고리>\n",
    "    \"\"\"\n",
    "\n",
    "    response = gemini_model.generate_content(prompt)\n",
    "    answer = response.text.strip()\n",
    "\n",
    "    place, sentiment = None, \"기타_중립\"\n",
    "    for line in answer.splitlines():\n",
    "        if line.startswith(\"매장명:\"):\n",
    "            place = line.replace(\"매장명:\", \"\").strip()\n",
    "        if line.startswith(\"감정:\"):\n",
    "            sentiment = line.replace(\"감정:\", \"\").strip()\n",
    "\n",
    "    return place, sentiment\n",
    "\n",
    "# -----------------------------\n",
    "# 5) 실행 부분 (Hybrid 적용)\n",
    "# -----------------------------\n",
    "def main():\n",
    "    CLEAN_FILE = \"data/cafe_posts_clean.csv\"\n",
    "    PLACE_INFO_FILE = \"data/jewelry_place_info_dict.json\"\n",
    "    SENTIMENT_DICT_FILE = \"data/place_sentiment_keywords_by_category.json\"\n",
    "\n",
    "    # ✅ 샘플링 제거 → 전체 데이터 사용\n",
    "    df = load_data(CLEAN_FILE)\n",
    "\n",
    "    place_info_dict = load_place_info_dict(PLACE_INFO_FILE)\n",
    "    sentiment_dict = load_sentiment_dict(SENTIMENT_DICT_FILE)\n",
    "    sentiment_categories = list(sentiment_dict.keys())\n",
    "\n",
    "    results = []\n",
    "    for _, row in df.iterrows():\n",
    "        text = f\"{row.get('title','')} {row.get('text','')} {row.get('comments','')}\"\n",
    "\n",
    "        # 1) Rule 기반 먼저 시도\n",
    "        place = normalize_place_rule(text, place_info_dict)\n",
    "        sentiment = classify_sentiment_rule(text, sentiment_dict)\n",
    "\n",
    "        # 2) Rule 실패 시 LLM 호출\n",
    "        if not place or not sentiment:\n",
    "            place_llm, sentiment_llm = classify_with_llm(text, place_info_dict, sentiment_categories)\n",
    "            place = place or place_llm\n",
    "            sentiment = sentiment or sentiment_llm\n",
    "\n",
    "        if place:\n",
    "            info = place_info_dict.get(place, {})\n",
    "            record = {\n",
    "                \"article_id\": row.get(\"naver_article_id\", None),\n",
    "                \"place_name\": place,\n",
    "                \"pbrand_name\": info.get(\"pbrand_name\"),\n",
    "                \"location_lv1\": info.get(\"location_lv1\"),\n",
    "                \"location_lv2\": info.get(\"location_lv2\"),\n",
    "                \"sentiment\": sentiment\n",
    "            }\n",
    "\n",
    "            # 모두 None 또는 \"None\"이면 제외\n",
    "            if not all((record.get(k) is None or record.get(k) == \"None\") for k in [\"place_name\", \"pbrand_name\", \"location_lv1\", \"location_lv2\"]):\n",
    "                results.append(record)\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # ✅ 전체 결과 CSV 저장\n",
    "    OUTPUT_FILE = \"data/labeled_sentiment_all.csv\"\n",
    "    save_csv(results_df, OUTPUT_FILE)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8114b3b",
   "metadata": {},
   "source": [
    "sentiment2.csv : 불러오기 n=100, random state=42 -> 15행, 정확도 약 50%\n",
    "sentiment3.csv : 불러오기 n=100, random state 제거 -> 11행, 정확도 약 15%\n",
    "sentiment4.csv : 불러오기 n=50, main n=50, random state 제거 -> 11행, 정확도 약 15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e40cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai  # Gemini SDK\n",
    "\n",
    "# ------------------------\n",
    "# ① 환경설정 & API 키 불러오기\n",
    "# ------------------------\n",
    "load_dotenv()\n",
    "google_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if not google_key:\n",
    "    raise ValueError(\"환경변수 GOOGLE_API_KEY가 없습니다. .env 파일 확인!\")\n",
    "\n",
    "# ------------------------\n",
    "# ② Gemini 클라이언트 초기화\n",
    "# ------------------------\n",
    "genai.configure(api_key=google_key)\n",
    "gemini_model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "# ------------------------\n",
    "# ✅ CSV 저장 헬퍼 함수\n",
    "# ------------------------\n",
    "def save_csv(df: pd.DataFrame, path: str):\n",
    "    \"\"\"DataFrame을 안전하게 CSV로 저장\"\"\"\n",
    "    df.to_csv(path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"✅ CSV 저장 완료: {path}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 1) 데이터 불러오기 + 샘플링\n",
    "# -----------------------------\n",
    "def load_and_sample(filepath: str, n=100, random_state=42) -> pd.DataFrame:\n",
    "    df = pd.read_csv(filepath)\n",
    "    sample_df = df.sample(n=n, random_state=random_state)\n",
    "    return sample_df.reset_index(drop=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) 매장명 정규화 (Rule 기반)\n",
    "# -----------------------------\n",
    "def load_place_info_dict(path: str) -> dict:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def normalize_place_rule(text: str, place_info_dict: dict) -> str | None:\n",
    "    for standard, info in place_info_dict.items():\n",
    "        for syn in info[\"synonyms\"]:\n",
    "            if syn and re.search(re.escape(syn), text, flags=re.IGNORECASE):\n",
    "                return standard\n",
    "    return None\n",
    "\n",
    "# -----------------------------\n",
    "# 3) 감정 분류 (Rule 기반)\n",
    "# -----------------------------\n",
    "def load_sentiment_dict(path: str) -> dict:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def classify_sentiment_rule(text: str, sentiment_dict: dict) -> str | None:\n",
    "    for category, keywords in sentiment_dict.items():\n",
    "        if any(kw in text for kw in keywords):\n",
    "            return category\n",
    "    return None\n",
    "\n",
    "# -----------------------------\n",
    "# 4) LLM 보완 (Gemini)\n",
    "# -----------------------------\n",
    "def classify_with_llm(text: str, place_info_dict: dict, sentiment_categories: list[str]) -> tuple[str, str]:\n",
    "    prompt = f\"\"\"\n",
    "    다음 텍스트에서 언급된 매장명을 표준 매장명으로 추출하고,\n",
    "    감정은 아래 카테고리 중 가장 적합한 하나를 선택해줘.\n",
    "\n",
    "    텍스트: {text}\n",
    "\n",
    "    매장 후보 (예시): {list(place_info_dict.keys())[:20]}\n",
    "\n",
    "    감정 카테고리 후보:\n",
    "    {sentiment_categories}\n",
    "\n",
    "    출력 형식:\n",
    "    매장명: <표준매장명 또는 None>\n",
    "    감정: <카테고리>\n",
    "    출력은 반드시 JSON 형식으로만 했으면 해.\n",
    "    예: {\"매장명\": \"현대백화점 무역센터점\", \"감정\": \"인테리어_긍정\"}\n",
    "    \"\"\"\n",
    "\n",
    "    response = gemini_model.generate_content(prompt)\n",
    "    answer = response.text.strip()\n",
    "\n",
    "    place, sentiment = None, \"기타_중립\"\n",
    "    for line in answer.splitlines():\n",
    "        if line.startswith(\"매장명:\"):\n",
    "            place = line.replace(\"매장명:\", \"\").strip()\n",
    "        if line.startswith(\"감정:\"):\n",
    "            sentiment = line.replace(\"감정:\", \"\").strip()\n",
    "\n",
    "    return place, sentiment\n",
    "\n",
    "# -----------------------------\n",
    "# 5) 실행 부분 (Hybrid 적용)\n",
    "# -----------------------------\n",
    "def main():\n",
    "    CLEAN_FILE = \"data/cafe_posts_clean.csv\"\n",
    "    PLACE_INFO_FILE = \"data/jewelry_place_info_dict.json\"\n",
    "    SENTIMENT_DICT_FILE = \"data/place_sentiment_keywords_by_category.json\"\n",
    "\n",
    "    df = load_and_sample(CLEAN_FILE, n=50, random_state=42)\n",
    "    place_info_dict = load_place_info_dict(PLACE_INFO_FILE)\n",
    "    sentiment_dict = load_sentiment_dict(SENTIMENT_DICT_FILE)\n",
    "    sentiment_categories = list(sentiment_dict.keys())\n",
    "\n",
    "    results = []\n",
    "    for _, row in df.iterrows():\n",
    "        text = f\"{row.get('title','')} {row.get('text','')} {row.get('comments','')}\"\n",
    "\n",
    "        # 1) Rule 기반 먼저 시도\n",
    "        place = normalize_place_rule(text, place_info_dict)\n",
    "        sentiment = classify_sentiment_rule(text, sentiment_dict)\n",
    "\n",
    "        # 2) Rule 실패 시 LLM 호출\n",
    "        if not place or not sentiment:\n",
    "            place_llm, sentiment_llm = classify_with_llm(text, place_info_dict, sentiment_categories)\n",
    "            place = place or place_llm\n",
    "            sentiment = sentiment or sentiment_llm\n",
    "\n",
    "        if place:\n",
    "            info = place_info_dict.get(place, {})\n",
    "            record = {\n",
    "                \"article_id\": row.get(\"naver_article_id\", None),\n",
    "                \"place_name\": place,\n",
    "                \"pbrand_name\": info.get(\"pbrand_name\"),\n",
    "                \"location_lv1\": info.get(\"location_lv1\"),\n",
    "                \"location_lv2\": info.get(\"location_lv2\"),\n",
    "                \"sentiment\": sentiment\n",
    "            }\n",
    "\n",
    "            # 모두 None 또는 \"None\"이면 제외\n",
    "            if not all((record.get(k) is None or record.get(k) == \"None\") for k in [\"place_name\", \"pbrand_name\", \"location_lv1\", \"location_lv2\"]):\n",
    "                results.append(record)\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    # print(\"\\n=== 라벨링 결과 미리보기 (상위 5행) ===\")\n",
    "    # print(results_df.head(5))\n",
    "    \n",
    "    # ✅ 결과 CSV 저장\n",
    "    OUTPUT_FILE = \"data/labeled_sample_sentiment2.csv\"\n",
    "    save_csv(results_df, OUTPUT_FILE)\n",
    "\n",
    "   \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79743f73",
   "metadata": {},
   "source": [
    "전체 행 대상으로 하되 변경사항 \n",
    "1. if not place or not sentiment 조건을 AND 조건으로 변경 -> Gemini 호출횟수 완화\n",
    "2. 얼마나 진행됐는지 진행률 확인 코드 추가\n",
    "3. 일단 200행만 돌려서 평균 처리 속도 측정 \n",
    "\n",
    "라벨링 진행중: 5%, 617/11969, 8m30s -> 이대로면 완료까지 3시간 예상. 스탑."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd2f69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai  # Gemini SDK\n",
    "from tqdm import tqdm   # ✅ 진행률 표시\n",
    "\n",
    "# ------------------------\n",
    "# ① 환경설정 & API 키 불러오기\n",
    "# ------------------------\n",
    "load_dotenv()\n",
    "google_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if not google_key:\n",
    "    raise ValueError(\"환경변수 GOOGLE_API_KEY가 없습니다. .env 파일 확인!\")\n",
    "\n",
    "# ------------------------\n",
    "# ② Gemini 클라이언트 초기화\n",
    "# ------------------------\n",
    "genai.configure(api_key=google_key)\n",
    "gemini_model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "# ------------------------\n",
    "# ✅ CSV 저장 헬퍼 함수\n",
    "# ------------------------\n",
    "def save_csv(df: pd.DataFrame, path: str):\n",
    "    \"\"\"DataFrame을 안전하게 CSV로 저장\"\"\"\n",
    "    df.to_csv(path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"✅ CSV 저장 완료: {path}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 1) 데이터 불러오기 (전체 데이터 사용)\n",
    "# -----------------------------\n",
    "def load_data(filepath: str) -> pd.DataFrame:\n",
    "    \"\"\"CSV 파일 전체 불러오기\"\"\"\n",
    "    return pd.read_csv(filepath)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) 매장명 정규화 (Rule 기반)\n",
    "# -----------------------------\n",
    "def load_place_info_dict(path: str) -> dict:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def normalize_place_rule(text: str, place_info_dict: dict) -> str | None:\n",
    "    for standard, info in place_info_dict.items():\n",
    "        for syn in info[\"synonyms\"]:\n",
    "            if syn and re.search(re.escape(syn), text, flags=re.IGNORECASE):\n",
    "                return standard\n",
    "    return None\n",
    "\n",
    "# -----------------------------\n",
    "# 3) 감정 분류 (Rule 기반)\n",
    "# -----------------------------\n",
    "def load_sentiment_dict(path: str) -> dict:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def classify_sentiment_rule(text: str, sentiment_dict: dict) -> str | None:\n",
    "    for category, keywords in sentiment_dict.items():\n",
    "        if any(kw in text for kw in keywords):\n",
    "            return category\n",
    "    return None\n",
    "\n",
    "# -----------------------------\n",
    "# 4) LLM 보완 (Gemini)\n",
    "# -----------------------------\n",
    "def classify_with_llm(text: str, place_info_dict: dict, sentiment_categories: list[str]) -> tuple[str, str]:\n",
    "    prompt = f\"\"\"\n",
    "    다음 텍스트에서 언급된 매장명을 표준 매장명으로 추출하고,\n",
    "    감정은 아래 카테고리 중 가장 적합한 하나를 선택해줘.\n",
    "\n",
    "    텍스트: {text}\n",
    "\n",
    "    매장 후보 (예시): {list(place_info_dict.keys())[:20]}\n",
    "\n",
    "    감정 카테고리 후보:\n",
    "    {sentiment_categories}\n",
    "\n",
    "    출력 형식:\n",
    "    매장명: <표준매장명 또는 None>\n",
    "    감정: <카테고리>\n",
    "    \"\"\"\n",
    "\n",
    "    response = gemini_model.generate_content(prompt)\n",
    "    answer = response.text.strip()\n",
    "\n",
    "    place, sentiment = None, \"기타_중립\"\n",
    "    for line in answer.splitlines():\n",
    "        if line.startswith(\"매장명:\"):\n",
    "            place = line.replace(\"매장명:\", \"\").strip()\n",
    "        if line.startswith(\"감정:\"):\n",
    "            sentiment = line.replace(\"감정:\", \"\").strip()\n",
    "\n",
    "    return place, sentiment\n",
    "\n",
    "# -----------------------------\n",
    "# 5) 실행 부분 (Hybrid 적용)\n",
    "# -----------------------------\n",
    "def main():\n",
    "    CLEAN_FILE = \"data/cafe_posts_clean.csv\"\n",
    "    PLACE_INFO_FILE = \"data/jewelry_place_info_dict.json\"\n",
    "    SENTIMENT_DICT_FILE = \"data/place_sentiment_keywords_by_category.json\"\n",
    "\n",
    "    df = load_data(CLEAN_FILE)\n",
    "    place_info_dict = load_place_info_dict(PLACE_INFO_FILE)\n",
    "    sentiment_dict = load_sentiment_dict(SENTIMENT_DICT_FILE)\n",
    "    sentiment_categories = list(sentiment_dict.keys())\n",
    "\n",
    "    results = []\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # ✅ tqdm으로 진행률 표시\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"라벨링 진행중\"):\n",
    "        text = f\"{row.get('title','')} {row.get('text','')} {row.get('comments','')}\"\n",
    "\n",
    "        # 1) Rule 기반 먼저 시도\n",
    "        place = normalize_place_rule(text, place_info_dict)\n",
    "        sentiment = classify_sentiment_rule(text, sentiment_dict)\n",
    "\n",
    "        # ✅ 조건 완화: 매장명 & 감정 둘 다 실패했을 때만 LLM 호출\n",
    "        if not place and not sentiment:\n",
    "            place_llm, sentiment_llm = classify_with_llm(text, place_info_dict, sentiment_categories)\n",
    "            place = place or place_llm\n",
    "            sentiment = sentiment or sentiment_llm\n",
    "\n",
    "        if place:\n",
    "            info = place_info_dict.get(place, {})\n",
    "            record = {\n",
    "                \"article_id\": row.get(\"naver_article_id\", None),\n",
    "                \"place_name\": place,\n",
    "                \"pbrand_name\": info.get(\"pbrand_name\"),\n",
    "                \"location_lv1\": info.get(\"location_lv1\"),\n",
    "                \"location_lv2\": info.get(\"location_lv2\"),\n",
    "                \"sentiment\": sentiment\n",
    "            }\n",
    "\n",
    "            # 모두 None 또는 \"None\"이면 제외\n",
    "            if not all((record.get(k) is None or record.get(k) == \"None\")\n",
    "                       for k in [\"place_name\", \"pbrand_name\", \"location_lv1\", \"location_lv2\"]):\n",
    "                results.append(record)\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # ✅ 전체 결과 CSV 저장\n",
    "    OUTPUT_FILE = \"data/labeled_sentiment_all.csv\"\n",
    "    save_csv(results_df, OUTPUT_FILE)\n",
    "\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"\\n⏱ 전체 처리 시간: {elapsed/60:.2f}분\")\n",
    "    print(f\"📊 최종 결과 행 수: {results_df.shape[0]}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8b09b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "라벨링 진행중: 5%, 617/11969, 8m30s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0865b1a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
