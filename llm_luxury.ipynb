{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101b5530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib, traceback, reluxury.pplx_client as pplx_client, inspect\n",
    "print(\"module file:\", pplx_client.__file__)\n",
    "print(\"has PPLXClient?\", \"PPLXClient\" in dir(pplx_client))\n",
    "if \"PPLXClient\" not in dir(pplx_client):\n",
    "    # 파일 내용을 실제로 확인 (앞 60줄)\n",
    "    import pathlib\n",
    "    src = pathlib.Path(pplx_client.__file__).read_text(encoding=\"utf-8\")\n",
    "    print(\"--- file head ---\")\n",
    "    print(\"\\n\".join(src.splitlines()[:60]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b92aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b2d104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "\n",
    "df_items = pd.read_csv('data/jewelry_items_word_with_category.csv')\n",
    "df_sentiment = pd.read_csv('data/jewelry_sentiment_words.csv')\n",
    "df_clean = pd.read_csv('data/cafe_posts_clean.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8ade94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f74012e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d32cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc73e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "pplx_client.py\n",
    "Perplexity API 호출용 기본 클라이언트 (OpenAI SDK 호환)\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "class PPLXClient:\n",
    "    \"\"\"Perplexity API 래퍼 클래스\"\"\"\n",
    "\n",
    "    def __init__(self, model: str = \"sonar\"):\n",
    "        load_dotenv()\n",
    "        api_key = os.getenv(\"PPLX_API_KEY\")\n",
    "        if not api_key:\n",
    "            raise ValueError(\"환경변수 PPLX_API_KEY를 설정해주세요.\")\n",
    "\n",
    "        self.client = OpenAI(api_key=api_key, base_url=\"https://api.perplexity.ai\")\n",
    "        self.model = model\n",
    "\n",
    "    def ask(self, prompt: str, system_prompt: str = \"Be precise and concise.\") -> str:\n",
    "        \"\"\"단건 호출\"\"\"\n",
    "        resp = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "        )\n",
    "        return resp.choices[0].message.content\n",
    "\n",
    "    def ask_stream(self, prompt: str, system_prompt: str = \"Be precise and concise.\"):\n",
    "        \"\"\"스트리밍 호출\"\"\"\n",
    "        stream = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            stream=True,\n",
    "        )\n",
    "        for chunk in stream:\n",
    "            delta = chunk.choices[0].delta\n",
    "            if delta and delta.content:\n",
    "                yield delta.content\n",
    "\n",
    "    @staticmethod\n",
    "    def preview_table(df: pd.DataFrame, n: int = 5) -> str:\n",
    "        \"\"\"데이터 미리보기 텍스트 생성\"\"\"\n",
    "        return df.head(n).to_markdown(index=False)\n",
    "\n",
    "    def ask_about_csv(self, df: pd.DataFrame, question: str) -> str:\n",
    "        \"\"\"CSV 미리보기 + 질문\"\"\"\n",
    "        context = self.preview_table(df, n=5)\n",
    "        prompt = (\n",
    "            \"당신은 초보 데이터 분석가입니다. 아래 표를 참고해 질문에 답하세요.\\n\\n\"\n",
    "            f\"{context}\\n\\n질문: {question}\"\n",
    "        )\n",
    "        return self.ask(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc383080",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U openai python-dotenv pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e5b81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d3ea15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예시 코드 1\n",
    "# # CSV 로드\n",
    "df_items = pd.read_csv('data/jewelry_items_word_with_category.csv')\n",
    "\n",
    "from reluxury.pplx_client import PPLXClient\n",
    "client = PPLXClient(model=\"sonar\")\n",
    "\n",
    "print(client.ask(\"한 문장으로 자기소개 예시를 만들어줘.\", temperature=0.2))\n",
    "print(client.ask_about_df(df_items, \"이 데이터의 주요 컬럼 3개만 뽑아 설명해줘.\"))\n",
    "for tok in client.ask_stream(\"한국의 수도는?\", temperature=0.0):\n",
    "    print(tok, end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fc32c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예시 코드 2\n",
    "\n",
    "import pandas as pd\n",
    "from reluxury.pplx_client import PPLXClient\n",
    "\n",
    "# 1) CSV 불러오기\n",
    "df_items = pd.read_csv('data/jewelry_items_word_with_category.csv')\n",
    "df_sentiment = pd.read_csv('data/jewelry_sentiment_words.csv')\n",
    "\n",
    "\n",
    "# 2) 클라이언트 초기화\n",
    "pplx = PPLXClient(model=\"sonar\")\n",
    "\n",
    "# 3) 일반 질문\n",
    "print(pplx.ask(\"한 문장으로 자기소개 예시를 만들어줘.\"))\n",
    "\n",
    "# 4) CSV 기반 질문\n",
    "print(pplx.ask_about_df(df_items, \"이 데이터의 주요 컬럼 3개만 뽑아 설명해줘.\"))\n",
    "\n",
    "# 5) 스트리밍 출력\n",
    "for token in pplx.ask_stream(\"스트리밍으로 한국의 수도를 알려줘.\"):\n",
    "    print(token, end=\"\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fb80c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예시 코드 3\n",
    "\n",
    "import pandas as pd\n",
    "from reluxury.pplx_client import PPLXClient\n",
    "\n",
    "# CSV 로드\n",
    "df_items = pd.read_csv('data/jewelry_items_word_with_category.csv')\n",
    "df_sentiment = pd.read_csv('data/jewelry_sentiment_words.csv')\n",
    "\n",
    "# 클라이언트\n",
    "client = PPLXClient(model=\"sonar\")  # 필요 시 \"sonar-pro\" 등\n",
    "\n",
    "# 1) 단건 질문\n",
    "print(client.ask(\"데이터 분석가의 역량 알려줘\", temperature=0.7))\n",
    "\n",
    "# 2) 메시지 배열\n",
    "msgs = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Summarize the benefits of model quantization in 2 bullets.\"},\n",
    "]\n",
    "print(client.chat(msgs, temperature=0.3))\n",
    "\n",
    "# 3) 스트리밍\n",
    "for token in client.ask_stream(\"한국의 수도는?\", temperature=0.0):\n",
    "    print(token, end=\"\", flush=True)\n",
    "\n",
    "# 4) DataFrame 기반 Q&A\n",
    "print(client.ask_about_df(df_items, \"이 데이터의 주요 컬럼 3개만 뽑아 설명해줘.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d066c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # .env 읽기\n",
    "print(\"키 확인:\", os.getenv(\"PPLX_API_KEY\")[:8] if os.getenv(\"PPLX_API_KEY\") else None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f558532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3f0763",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\"/Users/t2024-m0246/Downloads/sparta-project/luxury/.env\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990b67fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "print(\"dotenv 모듈 위치:\", dotenv.__file__)\n",
    "print(\"dotenv 모듈 버전:\", dotenv.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbe8a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip show python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf2ccf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 잘못된 dotenv 제거\n",
    "\n",
    "%pip uninstall -y dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd5582b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 올바른 패키지 설치/업데이트\n",
    "\n",
    "%pip install -U python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752b8237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.metadata\n",
    "print(importlib.metadata.version(\"python-dotenv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b910d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2572c11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1636ac03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.metadata\n",
    "print(importlib.metadata.version(\"python-dotenv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e70726",
   "metadata": {},
   "source": [
    "세팅완료 !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc1c26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from reluxury.pplx_client import PPLXClient\n",
    "\n",
    "# 1) CSV 불러오기\n",
    "df_items = pd.read_csv('data/jewelry_items_word_with_category.csv')\n",
    "df_sentiment = pd.read_csv('data/jewelry_sentiment_words.csv')\n",
    "df_clean = pd.read_csv('data/cafe_posts_clean.csv')\n",
    "\n",
    "# 2) 클라이언트 초기화\n",
    "pplx = PPLXClient(model=\"sonar\")\n",
    "\n",
    "# 3) 일반 질문\n",
    "# print(pplx.ask(\"한 문장으로 자기소개 예시를 만들어줘.\"))\n",
    "\n",
    "# 4) CSV 기반 질문\n",
    "# print(pplx.ask_about_df(df_items, df_sentiment, df_clean \"\")) # 이러면 에러남.\n",
    "# df 파일 하나씩 넣거나 통합된 DataFrame으로 넣어줘야 함. \n",
    "\n",
    "# # 질문예시 1. df_items (브랜드/라인 정보)\n",
    "# print(pplx.ask_about_df(df_items, \"브랜드명이 IWC인 제품 라인 이름들을 알려줘.\"))\n",
    "# print(pplx.ask_about_df(df_items, \"relative_word 컬럼에 등록된 별칭이 가장 많은 브랜드는 어디야?\"))\n",
    "\n",
    "# 질문예시 2. df_sentiment (감성 단어 사전)\n",
    "# print(pplx.ask_about_df(df_sentiment, \"긍정 카테고리에 해당하는 단어들은 몇 개인지 알려줘.\"))\n",
    "# print(pplx.ask_about_df(df_sentiment, \"부정 카테고리에 속한 단어 예시 5개만 보여줘.\"))\n",
    "\n",
    "# 질문예시 3. df_clean (카페 게시글)\n",
    "# print(pplx.ask_about_df(df_clean, \"조회수가 가장 높은 게시글의 제목을 알려줘.\"))\n",
    "print(pplx.ask_about_df(df_clean, \"댓글 수가 많은 게시글의 제목 3개만 뽑아줘.\"))\n",
    "\n",
    "# 5) 스트리밍 출력\n",
    "# for token in pplx.ask_stream(\"스트리밍으로 한국의 수도를 알려줘.\"):\n",
    "#     print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c411ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items, df_sentiment, df_clean 를 함께 활용해서 → 긍정 단어가 가장 많이 나온 제품명을 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b4eb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a38a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953a6e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4714def3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시간 오래 걸림 주의 (필자는 1m57.5s 소요됨)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# ---------- 0) 유틸 ----------\n",
    "def split_csv_list(s: str) -> list[str]:\n",
    "    \"\"\"쉼표로 구분된 문자열을 리스트로. 공백/빈값/NaN 안전 처리.\"\"\"\n",
    "    if pd.isna(s):\n",
    "        return []\n",
    "    return [x.strip() for x in str(s).split(\",\") if x.strip()]\n",
    "\n",
    "def safe_join_name(brand, line):\n",
    "    \"\"\"브랜드/라인 조합으로 제품명 라벨 생성\"\"\"\n",
    "    b = str(brand).strip() if pd.notna(brand) else \"\"\n",
    "    l = str(line).strip() if pd.notna(line) else \"\"\n",
    "    return f\"{b} {l}\".strip() if l else b\n",
    "\n",
    "# ---------- 1) 긍정 단어 사전 구축 ----------\n",
    "# df_sentiment: [category, words]\n",
    "mask_pos = df_sentiment[\"category\"].astype(str).str.endswith(\"긍정\")\n",
    "pos_words = []\n",
    "for words in df_sentiment.loc[mask_pos, \"words\"].dropna():\n",
    "    pos_words.extend(split_csv_list(words))\n",
    "\n",
    "# 중복 제거 & 길이 내림차순(긴 단어를 먼저 매칭해 부분중복 영향↓)\n",
    "pos_words = sorted(set(pos_words), key=len, reverse=True)\n",
    "# 긍정 단어 정규식 (특수문자 이스케이프)\n",
    "pos_re = re.compile(\"|\".join(map(re.escape, pos_words))) if pos_words else None\n",
    "\n",
    "# ---------- 2) 제품(별칭) 테이블 준비 ----------\n",
    "# df_items: [brand_id, brand_name, line_id, line_name, category_id, category_name, class_type, relative_word]\n",
    "items = df_items.copy()\n",
    "\n",
    "# 제품 라벨(출력용)\n",
    "items[\"product_label\"] = items.apply(lambda r: safe_join_name(r.get(\"brand_name\"), r.get(\"line_name\")), axis=1)\n",
    "\n",
    "# 별칭 리스트: relative_word + brand_name + line_name\n",
    "def build_aliases(row) -> list[str]:\n",
    "    aliases = set(split_csv_list(row.get(\"relative_word\")))\n",
    "    if pd.notna(row.get(\"brand_name\")) and str(row.get(\"brand_name\")).strip():\n",
    "        aliases.add(str(row.get(\"brand_name\")).strip())\n",
    "    if pd.notna(row.get(\"line_name\")) and str(row.get(\"line_name\")).strip():\n",
    "        aliases.add(str(row.get(\"line_name\")).strip())\n",
    "    # 길이 내림차순 (긴 별칭 우선 매칭)\n",
    "    return sorted({a for a in aliases if a}, key=len, reverse=True)\n",
    "\n",
    "items[\"aliases\"] = items.apply(build_aliases, axis=1)\n",
    "\n",
    "# 별칭 정규식(제품별)\n",
    "def compile_alias_re(aliases):\n",
    "    if not aliases:\n",
    "        return None\n",
    "    return re.compile(\"|\".join(map(re.escape, aliases)))\n",
    "items[\"alias_re\"] = items[\"aliases\"].apply(compile_alias_re)\n",
    "\n",
    "# ---------- 3) 콘텐츠 합치기 ----------\n",
    "# df_clean: [title, text, comments, ...]\n",
    "clean = df_clean.copy()\n",
    "for c in [\"title\", \"text\", \"comments\"]:\n",
    "    if c not in clean.columns:\n",
    "        clean[c] = \"\"\n",
    "clean[\"content\"] = (\n",
    "    clean[\"title\"].fillna(\"\").astype(str) + \"\\n\" +\n",
    "    clean[\"text\"].fillna(\"\").astype(str) + \"\\n\" +\n",
    "    clean[\"comments\"].fillna(\"\").astype(str)\n",
    ")\n",
    "\n",
    "contents = clean[\"content\"].tolist()  # 속도 때문에 리스트로 빼두기\n",
    "\n",
    "# ---------- 4) 제품별 긍정 단어 카운트 ----------\n",
    "results = []\n",
    "for idx, row in items.iterrows():\n",
    "    alias_re = row[\"alias_re\"]\n",
    "    if alias_re is None or pos_re is None:\n",
    "        pos_count = 0\n",
    "        doc_hits = 0\n",
    "    else:\n",
    "        pos_count = 0\n",
    "        doc_hits = 0\n",
    "        for doc in contents:\n",
    "            if alias_re.search(doc):              # 제품 언급된 글만 집계\n",
    "                doc_hits += 1\n",
    "                pos_count += len(pos_re.findall(doc))\n",
    "    results.append({\n",
    "        \"brand_id\": row.get(\"brand_id\"),\n",
    "        \"product_label\": row[\"product_label\"],\n",
    "        \"positive_word_count\": int(pos_count),\n",
    "        \"mentioned_docs\": int(doc_hits),\n",
    "        \"aliases\": row[\"aliases\"],\n",
    "        \"category_name\": row.get(\"category_name\"),\n",
    "        \"line_name\": row.get(\"line_name\"),\n",
    "    })\n",
    "\n",
    "result_df = pd.DataFrame(results)\n",
    "\n",
    "# ---------- 5) 상위 결과 확인 ----------\n",
    "topN = (\n",
    "    result_df.sort_values([\"positive_word_count\", \"mentioned_docs\"], ascending=[False, False])\n",
    "    .head(5)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(\"✅ 긍정 단어가 많이 언급된 상위 TOP5 제품\")\n",
    "print(topN[[\"product_label\", \"positive_word_count\", \"mentioned_docs\"]].to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aee1f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items = pd.read_csv(\"data/1.jewelry_items_word_with_category.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a95c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe842e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# 1) 정규화 사전 불러오기\n",
    "df_items = pd.read_csv(\"data/1.jewelry_items_word_with_category.csv\")  # variant, canonical\n",
    "replace_map = dict(zip(df_items[\"variant\"], df_items[\"canonical\"]))\n",
    "\n",
    "# 2) 치환 함수\n",
    "def normalize_text(text, mapping):\n",
    "    # 긴 단어부터 치환 (부분 매칭 방지)\n",
    "    pairs = sorted(mapping.items(), key=lambda kv: len(kv[0]), reverse=True)\n",
    "    for variant, canon in pairs:\n",
    "        text = re.sub(re.escape(variant), canon, text)\n",
    "    return text\n",
    "\n",
    "# 예시 텍스트\n",
    "raw = \"이 반지 진짜 예쁘네, 이쁘고 착용감도 좋아요!\"\n",
    "norm = normalize_text(raw, replace_map)\n",
    "print(\"정규화 전:\", raw)\n",
    "print(\"정규화 후:\", norm)\n",
    "\n",
    "# 3) LLM 호출\n",
    "from reluxury.pplx_client import PPLXClient\n",
    "client = PPLXClient(model=\"sonar\")\n",
    "\n",
    "print(client.ask(f\"아래 텍스트의 감성을 요약해줘:\\n{norm}\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff606823",
   "metadata": {},
   "source": [
    "정규화된 별도 파일이 필요함.\n",
    "왜냐하면 \"variant\" 해당하는 컬럼과 \"canonical\" 에 해당하는 컬럼으로 구분해서 LLM에 전달해야하는데 \n",
    "\n",
    "예를 들어 df_items 에서 \"variant\"는 \"relative_word\"가 되고\n",
    "\"canonical\" 이라는 대표성을 띄는 컬럼이 필요해. \n",
    "\n",
    "그래서 \"brand_id\" + \"line_id\" + \"cattegory_id\" 를 합친 컬럼을 하나 생성할거야. \n",
    "\n",
    "그런데 해당 파일에 공란들이 있어. \n",
    "이 공란을 메꾸는 작업이 1 첫번째 수행작업임. \n",
    "\n",
    "=> 우선은 공란 메꾸기 보다 \n",
    "불가리 제품의 인기템 3가지 디바스드림, 비제로원, 세르펜디 3가지만 가지고 해보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689e2084",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b3ce1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentiment.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b4a176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV 불러오기\n",
    "import pandas as pd \n",
    "df_items = pd.read_csv(\"data/1.jewelry_items_word_with_category.csv\")\n",
    "df_sentiment = pd.read_csv(\"data/2.jewelry_sentiment_words.csv\")\n",
    "df_place = pd.read_csv('data/3.jewelry_place_word_with_category.csv')\n",
    "df_place_sentiment = pd.read_csv('data/4.place_sentiment_keywords.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ead3580",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_place.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7872d8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_place_sentiment.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02bdb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_items 파일에서 불가리 인기템 3가지 라인 추출하자.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 파일 불러오기\n",
    "df_items = pd.read_csv(\"data/1.jewelry_items_word_with_category.csv\")\n",
    "\n",
    "# 조건에 맞는 line_id만 필터링\n",
    "target_ids = [\"l020\", \"l055\", \"l064\"]\n",
    "filtered = df_items[df_items[\"line_id\"].isin(target_ids)]\n",
    "\n",
    "print(filtered.head())\n",
    "print(\"총 행 개수:\", len(filtered))\n",
    "\n",
    "# 필요하다면 새로운 CSV로 저장\n",
    "filtered.to_csv(\"data/Bulgary_top3_items_filtered.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2727d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
